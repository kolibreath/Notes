夜跑项目新的思路

播放层： 使用java api播放 -> 内置一些wav文件 鼓点 节奏着一些  -> 记录下位置 ->最后合成一个wav


目标测试一下 aac文件合成的音频效果

[音频处理知识总结](https://blog.csdn.net/p2011211616/article/details/53432645)


先调研一下 那个项目音频合成的质量如何：

调研过程中备注：
音频基本处理知识总结

什么是aac文件

``采样频率``
采样频率，也称为采样速度或者采样率，定义了每秒从连续信号中提取并组成离散信号的采样个数 计算机每秒中采集多少个信号样本

人耳能够感受到的最高频率20khz 如果要满足人耳的听觉需求 至少需要每秒进行40k次采样，但是对于这些在自然世界中的信号，没有办法无线接近，为了复原波形，再一次振动过程中，必须有至少两个点的采样，最高点和最低点（正弦函数）


WAV和 PCM
wav是无损的音频的文件格式 PCM 是将声音的模拟信号转化为符号话的脉冲列，以01的形式存在，没有经过任何的编码和压缩处理，不容易受到chanting系统的杂波以及失真的影响 动态范围很宽

PcM 就是一种编码方式 wav等文件见也可以通过其他格式编码
[将录音格式文件转化为wav格式](https://www.jianshu.com/p/1d1f893e53e9)

PCM的码率 （数据传输速率是码率的八分之以）
采样率值×采样大小值×声道数bps 
一秒钟的数据传输速率是176KB/s 一分钟就是10.5M所以需要压缩

[Android audioRecorder](https://blog.csdn.net/jiangliloveyou/article/details/11218555)



aac 文件的混合情况
[AudioTrack](https://blog.csdn.net/qq_34161388/article/details/73776928)
什么是AudioTrack

surfaceView 
在子线程中更新ui 在底层实现了双缓冲机制

mediaPlayer AudioTrack AudioFlinger 
mediaPlayer 在播放的时候在底层还是创建了一个audioTrack 但是 在播放实时的音频的话只能使用AudioTrack


````
int bufsize = AudioTrack.getMinBufferSize(8000,//每秒8K个点  
  
　　AudioFormat.CHANNEL_CONFIGURATION_STEREO,//双声道  
  
AudioFormat.ENCODING_PCM_16BIT);//一个采样点16比特-2个字节 
````

采样率是8khz

````
AudioTrack trackplayer = new AudioTrack(AudioManager.STREAM_MUSIC, 8000,  
  
　　AudioFormat.CHANNEL_CONFIGURATION_ STEREO,  
  
　　AudioFormat.ENCODING_PCM_16BIT,  
  
　　bufsize,  
  
AudioTrack.MODE_STREAM);
````
mode_stream 就是说 java 层和 native层交互 一次一次地将数据写道AudioTrack

static 就是现将音频合数据放到一个固定的buffer 

AudioManager.Stream_music 就是告诉系统现在播放的音频的类型,