夜跑项目新的思路

播放层： 使用java api播放 -> 内置一些wav文件 鼓点 节奏着一些  -> 记录下位置 ->最后合成一个wav


目标测试一下 aac文件合成的音频效果

[音频处理知识总结](https://blog.csdn.net/p2011211616/article/details/53432645)


先调研一下 那个项目音频合成的质量如何：

调研过程中备注：
音频基本处理知识总结

什么是aac文件
Advanced Audio Coding 高级音频编码 
主要的扩展名有三种
.AAC
.MP4
.M4A

AAC的音频格式有ADIF和ADTS两种 
ADTS 可以在任意的frame解码 每一帧都有头信息


7个及总结的ADTSheader???

码率 文件大小除以播放时间 

[AAC格式分析](https://blog.csdn.net/BSPLover/article/details/7426476)

ADTS信息 :
头header信息 
- adts_fixed_header
syncWord 同步头 总是0xFFF 表示着一个ADTSframe的开始 12bit
id MPEG version  1bit
layer '00' always 2bits
profile 那种级别的aac 代码中定义的是low Complexity profile 2bit

源代码在输出的时候每一次都会给输出的buffer加上header header一共是7个字节
AAC 打包成为ADTS形式

``采样频率``
采样频率，也称为采样速度或者采样率，定义了每秒从连续信号中提取并组成离散信号的采样个数 计算机每秒中采集多少个信号样本

人耳能够感受到的最高频率20khz 如果要满足人耳的听觉需求 至少需要每秒进行40k次采样，但是对于这些在自然世界中的信号，没有办法无线接近，为了复原波形，再一次振动过程中，必须有至少两个点的采样，最高点和最低点（正弦函数）


WAV和 PCM
wav是无损的音频的文件格式 PCM 是将声音的模拟信号转化为符号话的脉冲列，以01的形式存在，没有经过任何的编码和压缩处理，不容易受到系统的杂波以及失真的影响 动态范围很宽

PcM 就是一种编码方式 wav等文件见也可以通过其他格式编码
[将录音格式文件转化为wav格式](https://www.jianshu.com/p/1d1f893e53e9)

PCM的码率 （数据传输速率）
采样大小值 -> 采样深度
采样率值×采样大小值×声道数bps 
一秒钟的数据传输速率是176KB/s 一分钟就是10.5M所以需要压缩

[Android audioRecorder](https://blog.csdn.net/jiangliloveyou/article/details/11218555)



aac 文件的混合情况
[AudioTrack](https://blog.csdn.net/qq_34161388/article/details/73776928)
什么是AudioTrack

surfaceView 
在子线程中更新ui 在底层实现了双缓冲机制

mediaPlayer AudioTrack AudioFlinger 
mediaPlayer 在播放的时候在底层还是创建了一个audioTrack 但是 在播放实时的音频的话只能使用AudioTrack


````
int bufsize = AudioTrack.getMinBufferSize(8000,//每秒8K个点  
  
　　AudioFormat.CHANNEL_CONFIGURATION_STEREO,//双声道  
  
AudioFormat.ENCODING_PCM_16BIT);//一个采样点16比特-2个字节 
````

采样率是8khz

````
AudioTrack trackplayer = new AudioTrack(AudioManager.STREAM_MUSIC, 8000,  
  
　　AudioFormat.CHANNEL_CONFIGURATION_ STEREO,  
  
　　AudioFormat.ENCODING_PCM_16BIT,  
  
　　bufsize,  
  
AudioTrack.MODE_STREAM);
````
第二个参数 其实就是一个采样率 比如 21250herz等
mode_stream 就是说 java 层和 native层交互 一次一次地将数据写道AudioTrack

static 就是现将音频合数据放到一个固定的buffer 

AudioManager.Stream_music 就是告诉系统现在播放的音频的类型,

Channel 声道 这里声道的概念和midi中声道的概念有很大的区别 midi中声道是由midi数据线接口的pin数量计算的 ，这里的声道只能1或者2 左声道和右声道

buffer： 最小buffer取决于 采样率 声道数和采样深度 三个属性
音频中也有frame的概念 

mediaCodec 
mediaformat 
[mediaCodec](https://wangyantao.github.io/mediacodec/)

生命周期工厂方法创建 -> executing -> stop 
可以在创建之后进行一系列的configure操作！


byteBuffer操作
[byteBuffer ](http://xiachaofeng.iteye.com/blog/1416634)




